## üéØ **Objectif du TP : D√©ployer l‚Äôapplication ‚Äúvote‚Äù avec Kubernetes**

### üß© **Contexte**
L'application "vote" est une architecture compos√©e de plusieurs microservices communiquant entre eux. Elle permet aux utilisateurs de voter pour une option (par exemple : "Cats" ou "Dogs") et d'afficher les r√©sultats en temps r√©el. Cette application est souvent utilis√©e comme exemple pour illustrer un d√©ploiement multi-conteneurs.

---

### üîß **Composants de l'application**

| Composant  | R√¥le                                                                 |
|------------|----------------------------------------------------------------------|
| `vote`     | Frontend web (√©crit en Python/Flask), pour voter                     |
| `result`   | Frontend web (√©crit en Node.js), pour voir les r√©sultats             |
| `worker`   | Service backend (√©crit en .NET), lit les votes depuis Redis et les stocke dans Postgres |
| `redis`    | File d‚Äôattente (in-memory queue) pour stocker les votes temporairement |
| `postgres` | Base de donn√©es relationnelle pour stocker les r√©sultats des votes   |

---

### üì¶ **Travail demand√©**

1. **Cr√©er un cluster Kubernetes (local ou distant)**  
   - Option : Minikube, Kind, K3s, MicroK8s ou un cluster cloud (GKE, AKS, EKS)

2. **D√©finir les manifests YAML n√©cessaires**
   - 1 Deployment par service : `vote`, `result`, `worker`, `redis`, `postgres`
   - 1 Service par composant, dont certains en `ClusterIP`, d'autres en `NodePort` ou `LoadBalancer`

3. **Configurer les services**
   - `vote` et `result` doivent √™tre accessibles depuis le navigateur
   - `worker` n‚Äôest pas expos√©, il communique en interne avec Redis et Postgres
   - `redis` et `postgres` sont uniquement accessibles depuis les autres pods

4. **D√©ployer tous les composants dans un namespace d√©di√©**  
   Exemple : `vote-app`


5. **Tester l‚Äôapplication**
   - Acc√©der √† l‚Äôinterface de vote
   - Voter plusieurs fois
   - V√©rifier que les r√©sultats s‚Äôaffichent en temps r√©el


**6. √âtendre l‚Äôapplication : types Kubernetes adapt√©s, collecte de logs, sauvegarde automatis√©e**

Dans cette nouvelle partie, vous allez transformer l‚Äôapplication pour qu‚Äôelle r√©ponde √† des exigences **r√©alistes de production**, en adaptant les types de d√©ploiement, en ajoutant une **collecte de logs centralis√©e**, et en automatisant la **sauvegarde de la base de donn√©es**.

#### A. Adapter les objets Kubernetes

1. **Analysez les besoins de chaque composant** et remplacez les `Deployment` par le type le plus appropri√©

#### B. Cr√©er et d√©ployer un syst√®me de collecte de logs

Vous allez cr√©er une **nouvelle application Python**, nomm√©e `log-reader`, et une **nouvelle base de donn√©es** appel√©e `log-db`.

1. **Cr√©er `log-db` :**

   * Il s‚Äôagit d‚Äôune nouvelle instance de **PostgreSQL** d√©di√©e au stockage des logs.
   * D√©ployez-la avec le bon type.
   * Exposez-la uniquement en interne.

2. **D√©velopper `log-reader` :**

   * Cette application Python doit :

     * Lire les logs stdout des pods (vous pouvez simuler cela via `/var/log/containers` ou en montant un volume de logs).
     * Ins√©rer ces logs dans la base `log-db`.

3. **D√©ployer `log-reader`** :

   * pour qu‚Äôun pod soit lanc√© sur chaque n≈ìud du cluster.
   * Cette application doit pouvoir se connecter √† `log-db` via un service interne.

#### C. Automatiser la sauvegarde avec une CronJob

1. **Cr√©er une application Python `db-dumper`** qui :

   * Effectue un dump de la base `postgres` (ex : avec `pg_dump`)
   * Archive le fichier (ex : `.tar.gz`)
   * L‚Äôenvoie par mail (via `smtplib`, ou un utilitaire syst√®me comme `mail`)

2. **D√©ployer l‚Äôapplication dans Kubernetes** :

   * Fr√©quence : **deux fois par jour** (ex : `0 6,18 * * *`)
   * Le conteneur doit inclure les outils n√©cessaires (client PostgreSQL, Python avec les bons modules)
   * Le mail peut √™tre simul√© avec un log

